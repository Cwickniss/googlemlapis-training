{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Google Cloud Vision API Samples\n",
    "This is an example notebook to see the Cloud Vision API in action via the Python Client Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Label Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here is the image that we are going to analyze and ask the Vision API to label it for us. We are going to be using the label_detection feature of the Vision library: <br/>\n",
    "<img src=\"https://cloud.google.com/vision/docs/images/faulkner.jpg\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Import the vision library\n",
    "from google.cloud import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create the client\n",
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Setup the image to be analyzed\n",
    "image = vision.types.Image()\n",
    "image.source.image_uri = \"https://cloud.google.com/vision/docs/images/faulkner.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Inboke the label_detection feature and get back the annotations\n",
    "response = client.label_detection(image=image)\n",
    "labels = response.label_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label= dog   score= 0.89\n",
      "label= dog like mammal   score= 0.89\n",
      "label= grass   score= 0.87\n",
      "label= dog breed   score= 0.87\n",
      "label= grassland   score= 0.72\n",
      "label= meadow   score= 0.65\n",
      "label= snout   score= 0.65\n",
      "label= english cocker spaniel   score= 0.63\n",
      "label= spaniel   score= 0.63\n",
      "label= pasture   score= 0.63\n"
     ]
    }
   ],
   "source": [
    "#Print out the labels that we received\n",
    "for label in labels:\n",
    "        print('label=',label.description,' ','score=',round(label.score,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Safe Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here is the image that we are going to analyze and ask the Vision API to perform Safe Search detection for us. We are going to be using the safe_search_detection feature of the Vision library: <br/>\n",
    "<img src=\"https://dvsgaming.org/wp-content/uploads/2017/01/Sniper-Elite-4_2-Melee-Kill-Cam-1024x576.jpg\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe search:\n",
      "adult: VERY_UNLIKELY\n",
      "medical: VERY_UNLIKELY\n",
      "spoofed: VERY_UNLIKELY\n",
      "violence: VERY_LIKELY\n"
     ]
    }
   ],
   "source": [
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "image = vision.types.Image()\n",
    "image.source.image_uri = \"https://dvsgaming.org/wp-content/uploads/2017/01/Sniper-Elite-4_2-Melee-Kill-Cam-1024x576.jpg\"\n",
    "response = client.safe_search_detection(image=image)\n",
    "safe = response.safe_search_annotation\n",
    "\n",
    "# Names of likelihood from google.cloud.vision.enums\n",
    "likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                       'LIKELY', 'VERY_LIKELY')\n",
    "print('Safe search:')\n",
    "\n",
    "print('adult: {}'.format(likelihood_name[safe.adult]))\n",
    "print('medical: {}'.format(likelihood_name[safe.medical]))\n",
    "print('spoofed: {}'.format(likelihood_name[safe.spoof]))\n",
    "print('violence: {}'.format(likelihood_name[safe.violence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Text Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here is the image that we are going to analyze and ask the Vision API to perform OCR for us. We are going to be using the text_detection feature of the Vision library: <br/>\n",
    "<img src=\"https://cloud.google.com/vision/docs/images/abbey_road.JPG\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts:\n",
      "\n",
      "\"ABBEY\n",
      "ROAD NW8\n",
      "CITY OF WESTMINSTER\n",
      "\"\n",
      "\n",
      "\"ABBEY\"\n",
      "\n",
      "\"ROAD\"\n",
      "\n",
      "\"NW8\"\n",
      "\n",
      "\"CITY\"\n",
      "\n",
      "\"OF\"\n",
      "\n",
      "\"WESTMINSTER\"\n"
     ]
    }
   ],
   "source": [
    "client = vision.ImageAnnotatorClient()\n",
    "image = vision.types.Image()\n",
    "image.source.image_uri = \"https://cloud.google.com/vision/docs/images/abbey_road.JPG\"\n",
    "\n",
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations\n",
    "print('Texts:')\n",
    "\n",
    "for text in texts:\n",
    "    print('\\n\"{}\"'.format(text.description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
